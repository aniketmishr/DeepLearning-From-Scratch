

# Transformer Implementation in PyTorch  

This directory contains an implementation of the Transformer model from the paper **"Attention Is All You Need"** using PyTorch. The model has been trained and can be directly used for inference via a Streamlit app.  

## Download Pre-trained Weights  
Download the pre-trained model weights from the link below:  
[Download Weights](https://drive.google.com/file/d/1-9gAZ-8a2k7izXqr3rABKQ5lbtHBfJb_/view?usp=sharing)  <!-- Replace with actual link -->

Move the weights file to the repository folder and rename the file with the following name : `model_weight.pt`.   

## Running the Streamlit App  
To start the Streamlit app, run:  
```bash
streamlit run streamlit_app.py  
```

## References  
- Umar Jamil *Attention is all you need* paper implementation [Video](https://youtu.be/ISNdQcPhsts?si=EpyTpzp96tgvYsZo)
- Vaswani et al., *Attention Is All You Need* (https://arxiv.org/abs/1706.03762)  
